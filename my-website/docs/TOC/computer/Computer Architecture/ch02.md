---
slug: Chapter Two Memory Hierachy Design
---

# Chapter Two Memory Hierachy Design

## 2.2 Ten Advanced Optimizations of Cache Performance

### First Optimization: Small and Simple First-Level Caches to Reduce Hit Time and Power

### Second Optimization: Way Prediction to Reduce Hit Time

### Third Optimization: Pipelined Cache Access to Increase Cache Bandwidth

### Fourth Optimization: Nonblocking Caches to Increase Cache Bandwidth

### Fifth Optimization: Multibanked Caches to Increase Cache Bandwidth

### Sixth Optimization: Critical Word First and Early Restart to Reduce Miss Penalty

### Seventh Optimization: Merging Write Buffer to Reduce Miss Penalty

### Eighth Optimization: Compiler Optimizations to Reduce Miss Rate

- _Loop Interchange_

```c
/* Before */
for (int i = 0; i < 1000; i = i +1){
        for (int j = 0; j < 500000; j = j +1) {
                int k = i*j;
        }
}
```

> ./t1 0.32s user 0.00s system 99% cpu 0.317 total

```c
/* After */
for (int i = 0; i < 500000; i = i +1) {
        for (int j = 0; j < 1000; j = j +1){
                int k = i*j;
        }
}
```

> ./t2 0.27s user 0.00s system 99% cpu 0.271 total

### Nineth Optimization: Hardware Prefetching of Instructions and Data to Reduce Miss Penalty or Miss Rate

### Tenth Optimization: Compiler-Controlled Prefetching to Reduce Miss Penalty or Miss Rate

- _Register prefetch_ will load the value into a register
- _Cache prefetch_ loads data only into the cache and not the register

### Cache Optimization Summary
